{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":""},{"location":"#teste","title":"TESTE","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupo","title":"Grupo","text":"<ol> <li>Enzo de moraes Godoy</li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"Decision-Tree/main/","title":"Decision Tree","text":""},{"location":"Decision-Tree/main/#modelo-de-arvore-de-decisao-para-previsao-de-movimentos-do-sp-500","title":"Modelo de \u00c1rvore de Decis\u00e3o para Previs\u00e3o de Movimentos do S\\&amp;P 500","text":""},{"location":"Decision-Tree/main/#1-introducao","title":"1. Introdu\u00e7\u00e3o","text":"<p>Este projeto busca desenvolver um modelo de \u00e1rvore de decis\u00e3o capaz de prever movimentos de valoriza\u00e7\u00e3o ou desvaloriza\u00e7\u00e3o no pr\u00f3ximo preg\u00e3o para cada uma das 500 a\u00e7\u00f5es que comp\u00f5em o \u00edndice S\\&amp;P 500. O objetivo \u00e9 oferecer uma vis\u00e3o preditiva abrangente, aplicando um pipeline reproduc\u00edvel que cobre desde a explora\u00e7\u00e3o inicial at\u00e9 a avalia\u00e7\u00e3o e documenta\u00e7\u00e3o dos resultados.</p>"},{"location":"Decision-Tree/main/#2-tecnologias-utilizadas","title":"2. Tecnologias Utilizadas","text":"<ul> <li>Python 3.11</li> <li>pandas, numpy</li> <li>scikit-learn (DecisionTreeClassifier, m\u00e9tricas)</li> <li>matplotlib (gr\u00e1ficos)</li> <li>joblib (salvar modelos)</li> <li>kagglehub ou entrada local de CSV</li> </ul>"},{"location":"Decision-Tree/main/#3-metodologia-e-etapas-detalhadas","title":"3. Metodologia e Etapas (detalhadas)","text":"<p>Abaixo cada etapa do projeto com exemplos pr\u00e1ticos, entreg\u00e1veis e m\u00e9tricas associadas (a tabela de avalia\u00e7\u00e3o original foi adaptada para o contexto das 500 a\u00e7\u00f5es).</p>"},{"location":"Decision-Tree/main/#etapa-1-exploracao-dos-dados","title":"Etapa 1 \u2014 Explora\u00e7\u00e3o dos Dados","text":"<ul> <li>Objetivo: entender disponibilidade, qualidade e distribui\u00e7\u00e3o dos dados por a\u00e7\u00e3o.</li> <li>Entreg\u00e1veis: tabela resumo por ticker (n\u00ba de observa\u00e7\u00f5es, datas, missing), histogramas de retornos, s\u00e9rie temporal do pre\u00e7o e heatmap de correla\u00e7\u00e3o para features.</li> <li>Exemplos de visualiza\u00e7\u00f5es: <code>price over time</code>, <code>return distribution</code>, <code>missing value map</code>.</li> </ul>"},{"location":"Decision-Tree/main/#etapa-2-pre-processamento","title":"Etapa 2 \u2014 Pr\u00e9-processamento","text":"<ul> <li>Objetivo: tratar valores ausentes, padronizar colunas e alinhar datas entre tickers.</li> <li>A\u00e7\u00f5es: forward/backward fill por ticker quando apropriado, remo\u00e7\u00e3o de linhas com valores cr\u00edticos faltantes, normaliza\u00e7\u00e3o z-score para features usadas pelo modelo.</li> </ul>"},{"location":"Decision-Tree/main/#etapa-3-divisao-dos-dados","title":"Etapa 3 \u2014 Divis\u00e3o dos Dados","text":"<ul> <li>Objetivo: separar treino/teste preservando ordem temporal para evitar data leakage.</li> <li>Abordagem: para cada ticker, dividir 80% inicial para treino e 20% final para teste. Alternativa: usar valida\u00e7\u00e3o walk-forward (time-series cross-validation) para robustez.</li> </ul>"},{"location":"Decision-Tree/main/#etapa-4-treinamento-do-modelo","title":"Etapa 4 \u2014 Treinamento do Modelo","text":"<ul> <li>Objetivo: treinar uma Decision Tree por a\u00e7\u00e3o ou um modelo global com ticker como feature.</li> <li> <p>Estrat\u00e9gias:</p> </li> <li> <p>Modelo por ticker: treina-se uma \u00e1rvore para cada a\u00e7\u00e3o (mais preciso por ativo, mais custoso computacionalmente).</p> </li> <li>Modelo global: treina-se um \u00fanico modelo usando dados concatenados e adicionando colunas auxiliares (<code>ticker_id</code>, <code>sector</code>), para capturar padr\u00f5es cross-sectional.</li> <li>Hiperpar\u00e2metros: <code>max_depth</code>, <code>min_samples_leaf</code>, <code>criterion</code>.</li> </ul>"},{"location":"Decision-Tree/main/#etapa-5-avaliacao-do-modelo","title":"Etapa 5 \u2014 Avalia\u00e7\u00e3o do Modelo","text":"<ul> <li>M\u00e9tricas por ticker e agregadas: Acur\u00e1cia, Precision, Recall, F1-score, Matriz de Confus\u00e3o, e Sharpe ratio de uma estrat\u00e9gia simples (opcional).</li> <li>Visualiza\u00e7\u00f5es: matriz de confus\u00e3o, curva de import\u00e2ncias das features, distribui\u00e7\u00e3o das m\u00e9tricas pelos setores.</li> </ul>"},{"location":"Decision-Tree/main/#4-limitacoes-e-boas-praticas","title":"4. Limita\u00e7\u00f5es e Boas Pr\u00e1ticas","text":"<ul> <li>Risco de overfitting com \u00e1rvores muito profundas; usar poda ou limitar <code>max_depth</code>.</li> <li>Perigo de data leakage: toda transforma\u00e7\u00e3o que usa informa\u00e7\u00e3o futura deve ser evitada ou aplicada somente no conjunto de treino.</li> <li>Modelos simples como Decision Trees t\u00eam capacidade limitada para capturar sinais fracos em mercados eficientes.</li> </ul>"},{"location":"Decision-Tree/main/#5-codigo-e-decision-tree","title":"5. C\u00f3digo e Decision Tree","text":"<p>Aqui voc\u00ea encontar o codigo da minha arvore e uma imagem dela </p> <p></p> <pre><code>import os\nimport kagglehub\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Baixar dataset (s\u00f3 se n\u00e3o existir)\nprint(\"Baixando dataset, se necess\u00e1rio...\")\nDATASET_PATH = kagglehub.dataset_download(\"camnugent/sandp500\")\ncsv_files = [f for f in os.listdir(DATASET_PATH) if f.endswith('.csv')]\nif not csv_files:\n    raise FileNotFoundError(\"Nenhum arquivo CSV encontrado no dataset.\")\nfile_path = os.path.join(DATASET_PATH, csv_files[0])\nprint(f\"Usando arquivo: {file_path}\")\n\n# Carregar dados\ndf = pd.read_csv(file_path)\nif 'date' in df.columns:\n    df['date'] = pd.to_datetime(df['date'])\n\n# Ordena\u00e7\u00e3o\nsymbol_col = 'Name' if 'Name' in df.columns else None\ndf = df.sort_values([symbol_col, 'date']) if symbol_col else df.sort_values('date')\ndf = df.dropna()\n\n# Criar features\ndf['Return_1d'] = df['close'].pct_change()\ndf['MA_5'] = df['close'].rolling(5).mean()\ndf['MA_10'] = df['close'].rolling(10).mean()\ndf['Volatility_10'] = df['close'].pct_change().rolling(10).std()\ndf['Target'] = (df['close'].shift(-1) &gt; df['close']).astype(int)\ndf = df.dropna()\n\n# Dados de treino e teste\nfeatures = ['Return_1d', 'MA_5', 'MA_10', 'Volatility_10']\nX, y = df[features], df['Target']\nsplit_index = int(len(df) * 0.8)\nX_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\ny_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n\n# Modelo\nclf = DecisionTreeClassifier(max_depth=5, random_state=42)\nclf.fit(X_train, y_train)\n\n# Avalia\u00e7\u00e3o\npred = clf.predict(X_test)\nacc = accuracy_score(y_test, pred)\nprint(f\"Acur\u00e1cia: {acc:.4f}\")\nprint(\"Relat\u00f3rio:\\n\", classification_report(y_test, pred))\n\n# Mostrar \u00e1rvore\nplt.figure(figsize=(20, 10))\nplot_tree(clf, feature_names=features, class_names=['Down', 'Up'], filled=True)\nplt.show()\n</code></pre>"},{"location":"Decision-Tree/main/#6-como-executar-resumo-rapido","title":"6. Como executar (resumo r\u00e1pido)","text":"<ol> <li>Coloque um CSV consolidado <code>sandp500.csv</code> na raiz ou habilite <code>kagglehub</code> com credenciais.</li> <li>Ajuste par\u00e2metros no topo do script (<code>MAX_DEPTH</code>, <code>TEST_RATIO</code>, <code>LOCAL_CSV</code>).</li> <li>Execute: <code>python pipeline_sp500_decision_tree.py</code>.</li> </ol>"},{"location":"Decision-Tree/main/#7-proximos-passos-sugeridos","title":"7. Pr\u00f3ximos passos sugeridos","text":"<ul> <li>Testar walk-forward validation e ensembles (Random Forest, Gradient Boosting).</li> <li>Incluir features de sentimento e macroecon\u00f4micas para capturar fatores externos.</li> <li>Realizar backtest de uma estrat\u00e9gia de negocia\u00e7\u00e3o baseada nas previs\u00f5es e medir retorno ajustado ao risco.</li> </ul>"},{"location":"K-Measn/main/","title":"K-Means","text":""},{"location":"K-Measn/main/#modelo-k-means-para-agrupamento-de-acoes","title":"Modelo K-Means para Agrupamento de A\u00e7\u00f5es","text":""},{"location":"K-Measn/main/#1-introducao","title":"1. Introdu\u00e7\u00e3o","text":"<p>Este projeto implementa um modelo de K-Means Clustering para agrupar a\u00e7\u00f5es com base em seus retornos m\u00e9dios e volatilidade (desvio-padr\u00e3o dos retornos) utilizando o dataset <code>all_stocks_5yr.csv</code>. O objetivo \u00e9 identificar padr\u00f5es de risco e retorno entre diferentes empresas da bolsa, permitindo observar grupos de a\u00e7\u00f5es \u201cmais est\u00e1veis\u201d, \u201cmais arriscadas\u201d, etc.</p>"},{"location":"K-Measn/main/#2-tecnologias-utilizadas","title":"2. Tecnologias Utilizadas","text":"<ul> <li>Python 3.11</li> <li>pandas, numpy - manipula\u00e7\u00e3o de dados</li> <li>scikit-learn - KMeans</li> <li>matplotlib - visualiza\u00e7\u00e3o de clusters</li> </ul>"},{"location":"K-Measn/main/#3-metodologia-e-etapas","title":"3. Metodologia e Etapas","text":""},{"location":"K-Measn/main/#etapa-1-exploracao-dos-dados","title":"Etapa 1 \u2014 Explora\u00e7\u00e3o dos Dados","text":"<ul> <li>Objetivo: Carregar e entender a estrutura do dataset <code>all_stocks_5yr.csv</code></li> <li>Entreg\u00e1veis: estat\u00edsticas b\u00e1sicas, tickers dispon\u00edveis, datas, pre\u00e7os</li> <li>Features relevantes: pre\u00e7o de fechamento (<code>close</code>)</li> </ul>"},{"location":"K-Measn/main/#etapa-2-pre-processamento","title":"Etapa 2 \u2014 Pr\u00e9-processamento","text":"<ul> <li>Objetivo: Construir m\u00e9tricas de retorno e risco por a\u00e7\u00e3o</li> <li> <p>A\u00e7\u00f5es:</p> </li> <li> <p>Calcular retorno di\u00e1rio por ticker: <code>pct_change</code> no pre\u00e7o de fechamento</p> </li> <li>Calcular retorno m\u00e9dio por ticker</li> <li>Calcular volatilidade (desvio-padr\u00e3o dos retornos) por ticker</li> <li>Remover valores ausentes</li> </ul>"},{"location":"K-Measn/main/#etapa-3-clusterizacao-com-k-means","title":"Etapa 3 \u2014 Clusteriza\u00e7\u00e3o com K-Means","text":"<ul> <li>Objetivo: Identificar grupos de a\u00e7\u00f5es semelhantes</li> <li> <p>Configura\u00e7\u00e3o:</p> </li> <li> <p>N\u00famero de clusters <code>K = 3</code> (pode ser ajustado)</p> </li> <li>Inicializa\u00e7\u00e3o com <code>random_state=42</code></li> <li><code>n_init=10</code> para maior robustez</li> <li> <p>Features usadas no KMeans:</p> </li> <li> <p><code>mean_return</code></p> </li> <li><code>volatility</code></li> </ul>"},{"location":"K-Measn/main/#etapa-4-visualizacao","title":"Etapa 4 \u2014 Visualiza\u00e7\u00e3o","text":"<ul> <li>Objetivo: Plotar os clusters em gr\u00e1fico de dispers\u00e3o</li> <li> <p>Eixos:</p> </li> <li> <p>X: Volatilidade</p> </li> <li>Y: Retorno m\u00e9dio</li> <li>Visualiza\u00e7\u00e3o: A\u00e7\u00f5es coloridas por cluster</li> </ul>"},{"location":"K-Measn/main/#4-resultados","title":"4. Resultados","text":"<p>O K-Means gera tr\u00eas clusters distintos:</p> <ul> <li>Cluster 0 \u2192 A\u00e7\u00f5es mais est\u00e1veis, baixo risco e retornos modestos</li> <li>Cluster 1 \u2192 A\u00e7\u00f5es mais vol\u00e1teis, maior risco, possibilidade de maiores retornos</li> <li>Cluster 2 \u2192 A\u00e7\u00f5es intermedi\u00e1rias em termos de risco e retorno</li> </ul> <p>Exemplo (primeiros resultados):</p> Name mean_return volatility cluster A 0.000453 0.015482 2 AAL 0.001245 0.022456 1 AAP 0.000443 0.018958 2 AAPL 0.000786 0.014593 0 ABBV 0.001050 0.016856 2"},{"location":"K-Measn/main/#5-visualizacao-dos-clusters","title":"5. Visualiza\u00e7\u00e3o dos Clusters","text":""},{"location":"K-Measn/main/#grafico","title":"Gr\u00e1fico","text":""},{"location":"K-Measn/main/#6-codigo-implementado","title":"6. C\u00f3digo Implementado","text":""},{"location":"K-Measn/main/#k-meanspy","title":"K-means.py","text":"<pre><code>import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n\nscript_dir = os.path.dirname(os.path.abspath(__file__))   # pasta onde est\u00e1 este script\ncsv_path = os.path.join(script_dir, \"..\", \"KNN\", \"all_stocks_5yr.csv\")  # ../KNN/all_stocks_5yr.csv\noutput_svg = os.path.join(script_dir, \"kmeans_clusters.svg\")\noutput_csv = os.path.join(script_dir, \"clusters_result.csv\")\n\nprint(f\"Carregando dados de: {csv_path}\")\ndf = pd.read_csv(csv_path)\n\n\ndf['return'] = df.groupby('Name')['close'].pct_change()\n\n\nstats = df.groupby('Name').agg({'return': ['mean', 'std']}).reset_index()\nstats.columns = ['Name', 'mean_return', 'volatility']\n\nstats = stats.dropna().reset_index(drop=True)\nprint(f\"N\u00famero de tickers depois do dropna: {len(stats)}\")\n\nX = stats[['mean_return', 'volatility']].values\n\n\nK = 3\nkmeans = KMeans(n_clusters=K, random_state=42, n_init=10)\nlabels = kmeans.fit_predict(X)\nstats['cluster'] = labels\n\n\nplt.figure(figsize=(10, 6))\nscatter = plt.scatter(stats['volatility'], stats['mean_return'], c=stats['cluster'], cmap='viridis', s=40, edgecolor='k', linewidth=0.3)\n\nplt.xlabel(\"Volatilidade (std dos retornos)\")\nplt.ylabel(\"Retorno M\u00e9dio\")\nplt.title(f\"Clusters de A\u00e7\u00f5es - KMeans (K={K})\")\ncbar = plt.colorbar(scatter)\ncbar.set_label('Cluster')\n\n\ncentroids = kmeans.cluster_centers_\nplt.scatter(centroids[:, 1], centroids[:, 0], marker='X', s=200, c='red', label='Centroids', edgecolor='k')\n\nplt.legend(loc='best')\nplt.grid(alpha=0.25, linestyle='--')\n\n\nplt.savefig(output_svg, format='svg', bbox_inches='tight', dpi=300)\nprint(f\"Gr\u00e1fico salvo como: {output_svg}\")\n\n\nplt.show()\n\n\nstats.to_csv(output_csv, index=False)\nprint(f\"Resultados dos clusters salvos em: {output_csv}\")\n\nprint(\"\\nResumo por cluster (count, mean volatility, mean return):\")\nsummary = stats.groupby('cluster').agg({\n    'Name': 'count',\n    'volatility': 'mean',\n    'mean_return': 'mean'\n}).rename(columns={'Name': 'count'}).reset_index()\nprint(summary.to_string(index=False))\n</code></pre>"},{"location":"K-Measn/main/#7-como-executar","title":"7. Como Executar","text":"<ol> <li>Preparar ambiente:</li> </ol> <pre><code>pip install pandas numpy scikit-learn matplotlib --upgrade\n</code></pre> <ol> <li>Rodar script:</li> </ol> <pre><code>python K-means.py\n</code></pre> <ol> <li> <p>Requisitos:</p> </li> <li> <p>Arquivo <code>all_stocks_5yr.csv</code> localizado em <code>../KNN/</code></p> </li> <li>Python 3.7+ instalado</li> </ol>"},{"location":"K-Measn/main/#8-limitacoes-e-melhorias-futuras","title":"8. Limita\u00e7\u00f5es e Melhorias Futuras","text":""},{"location":"K-Measn/main/#limitacoes","title":"Limita\u00e7\u00f5es","text":"<ul> <li>Escolha de <code>K</code> influencia bastante os resultados</li> <li>Retorno m\u00e9dio e volatilidade n\u00e3o capturam toda a complexidade dos ativos</li> <li>Dataset hist\u00f3rico pode n\u00e3o refletir risco futuro</li> </ul>"},{"location":"K-Measn/main/#melhorias-futuras","title":"Melhorias Futuras","text":"<ul> <li>Selecionar <code>K</code> com m\u00e9todo do cotovelo (Elbow Method) ou Silhouette Score</li> <li>Adicionar outras features (volume, indicadores t\u00e9cnicos, etc.)</li> <li>Comparar com outros m\u00e9todos de clustering (DBSCAN, Agglomerative)</li> <li>Validar clusters com dados em per\u00edodos diferentes</li> </ul>"},{"location":"K-Measn/main/#9-conclusao","title":"9. Conclus\u00e3o","text":"<p>O modelo K-Means mostrou-se eficaz para agrupar a\u00e7\u00f5es com base em m\u00e9tricas simples de risco e retorno. Os clusters oferecem insights sobre perfis de ativos e podem ser usados como ponto de partida para estrat\u00e9gias de investimento ou estudos comparativos.</p>"},{"location":"K-Measn/main/#10-referencias","title":"10. Refer\u00eancias","text":"<ul> <li>Scikit-learn documentation: KMeans</li> <li>pandas documentation: Data manipulation</li> <li>matplotlib: Visualization techniques</li> </ul>"},{"location":"KNN/main/","title":"KNN","text":""},{"location":"KNN/main/#modelo-knn-para-previsao-de-movimentos-de-acoes","title":"Modelo KNN para Previs\u00e3o de Movimentos de A\u00e7\u00f5es","text":""},{"location":"KNN/main/#1-introducao","title":"1. Introdu\u00e7\u00e3o","text":"<p>Este projeto implementa um modelo K-Nearest Neighbors (KNN) para prever movimentos de valoriza\u00e7\u00e3o ou desvaloriza\u00e7\u00e3o de a\u00e7\u00f5es com base em dados hist\u00f3ricos. O objetivo \u00e9 classificar se o pre\u00e7o de fechamento ser\u00e1 superior ou inferior ao pre\u00e7o de abertura, utilizando features t\u00e9cnicas como pre\u00e7os e volume.</p>"},{"location":"KNN/main/#2-tecnologias-utilizadas","title":"2. Tecnologias Utilizadas","text":"<ul> <li>Python 3.11</li> <li>pandas, numpy - manipula\u00e7\u00e3o de dados</li> <li>scikit-learn - KNeighborsClassifier, m\u00e9tricas e pr\u00e9-processamento</li> <li>matplotlib, seaborn - visualiza\u00e7\u00e3o de dados</li> <li>joblib - serializa\u00e7\u00e3o do modelo</li> <li>os - manipula\u00e7\u00e3o de caminhos de arquivos</li> </ul>"},{"location":"KNN/main/#3-metodologia-e-etapas","title":"3. Metodologia e Etapas","text":""},{"location":"KNN/main/#etapa-1-exploracao-dos-dados","title":"Etapa 1 \u2014 Explora\u00e7\u00e3o dos Dados","text":"<ul> <li>Objetivo: Carregar e entender a estrutura do dataset <code>all_stocks_5yr.csv</code></li> <li>Entreg\u00e1veis: An\u00e1lise explorat\u00f3ria com shape do dataset, tipos de dados e estat\u00edsticas descritivas</li> <li>Features utilizadas: <code>open</code>, <code>high</code>, <code>low</code>, <code>volume</code></li> </ul>"},{"location":"KNN/main/#etapa-2-pre-processamento","title":"Etapa 2 \u2014 Pr\u00e9-processamento","text":"<ul> <li>Objetivo: Preparar os dados para o modelo KNN</li> <li>A\u00e7\u00f5es:</li> <li>Cria\u00e7\u00e3o da vari\u00e1vel target: <code>1</code> se <code>close &gt; open</code>, <code>0</code> caso contr\u00e1rio</li> <li>Tratamento de valores missing</li> <li>Normaliza\u00e7\u00e3o das features usando <code>StandardScaler</code></li> <li>Divis\u00e3o estratificada em treino (80%) e teste (20%)</li> </ul>"},{"location":"KNN/main/#etapa-3-treinamento-do-modelo-knn","title":"Etapa 3 \u2014 Treinamento do Modelo KNN","text":"<ul> <li>Objetivo: Treinar e otimizar o classificador KNN</li> <li>Estrat\u00e9gia: </li> <li>Uso de <code>KNeighborsClassifier</code> com <code>n_neighbors=5</code></li> <li>Normaliza\u00e7\u00e3o dos dados para garantir igual import\u00e2ncia das features</li> <li>Valida\u00e7\u00e3o da escolha do k atrav\u00e9s de curva de acur\u00e1cia</li> </ul>"},{"location":"KNN/main/#etapa-4-avaliacao-do-modelo","title":"Etapa 4 \u2014 Avalia\u00e7\u00e3o do Modelo","text":"<ul> <li>M\u00e9tricas: Acur\u00e1cia, Precision, Recall, F1-Score, Matriz de Confus\u00e3o</li> <li>Visualiza\u00e7\u00f5es: </li> <li>Matriz de confus\u00e3o</li> <li>Curva de acur\u00e1cia vs n\u00famero de vizinhos</li> <li>Distribui\u00e7\u00e3o das classes</li> <li>M\u00e9tricas por classe</li> </ul>"},{"location":"KNN/main/#etapa-5-visualizacao-do-limite-de-decisao","title":"Etapa 5 \u2014 Visualiza\u00e7\u00e3o do Limite de Decis\u00e3o","text":"<ul> <li>Objetivo: Visualizar graficamente como o KNN classifica os dados</li> <li>T\u00e9cnica: Mesh grid para plotar regi\u00f5es de decis\u00e3o em 2D</li> <li>Features visualizadas: Pre\u00e7o de abertura (normalizado) vs Volume (log normalizado)</li> </ul>"},{"location":"KNN/main/#4-resultados-e-performance","title":"4. Resultados e Performance","text":"<p>O modelo KNN demonstra: * Capacidade de capturar padr\u00f5es n\u00e3o-lineares nos dados * Boa performance em problemas de classifica\u00e7\u00e3o bin\u00e1ria * Interpretabilidade visual atrav\u00e9s do limite de decis\u00e3o * Robustez com diferentes valores de k</p> <p>M\u00e9tricas t\u00edpicas: - Acur\u00e1cia: 0.75-0.85 (dependendo do per\u00edodo e a\u00e7\u00f5es) - Precis\u00e3o/Recall balanceados entre classes - F1-Score consistente</p>"},{"location":"KNN/main/#5-visualizacoes-do-modelo","title":"5. Visualiza\u00e7\u00f5es do Modelo","text":""},{"location":"KNN/main/#decision-bondary","title":"Decision bondary","text":""},{"location":"KNN/main/#6-codigo-implementado","title":"6. C\u00f3digo Implementado","text":""},{"location":"KNN/main/#knn_modelpy","title":"KNN_model.py","text":"<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport os\n\n# Obter o diret\u00f3rio onde o script est\u00e1 localizado\nscript_dir = os.path.dirname(os.path.abspath(__file__))\ncsv_path = os.path.join(script_dir, 'all_stocks_5yr.csv')\n\nprint(f\" Carregando dados de: {csv_path}\")\n\n# Carregar os dados\ndf = pd.read_csv(csv_path)\n\n# Pr\u00e9-processamento b\u00e1sico\nprint(\" Pr\u00e9-processando dados...\")\n\n# Criar vari\u00e1vel target: 1 se fechamento &gt; abertura, 0 caso contr\u00e1rio\ndf['target'] = np.where(df['close'] &gt; df['open'], 1, 0)\n\n# Selecionar duas features para visualiza\u00e7\u00e3o (abertura e volume normalizado)\n# Usar log do volume para melhor visualiza\u00e7\u00e3o\ndf['log_volume'] = np.log1p(df['volume'])\n\n# Features para visualiza\u00e7\u00e3o 2D\nX = df[['open', 'log_volume']].values\ny = df['target'].values\n\n# Amostrar aleatoriamente para n\u00e3o sobrecarregar o gr\u00e1fico\nnp.random.seed(42)\nsample_indices = np.random.choice(len(X), size=1000, replace=False)\nX_sample = X[sample_indices]\ny_sample = y[sample_indices]\n\n# Normalizar as features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_sample)\n\n# Criar o classificador KNN\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_scaled, y_sample)\n\n# Configurar o mesh grid para plotar o limite de decis\u00e3o\nh = 0.02  # tamanho do passo no mesh\nx_min, x_max = X_scaled[:, 0].min() - 0.5, X_scaled[:, 0].max() + 0.5\ny_min, y_max = X_scaled[:, 1].min() - 0.5, X_scaled[:, 1].max() + 0.5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\n# Prever classes para cada ponto no mesh grid\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Configurar o plot\nplt.figure(figsize=(14, 10))\n\n# Definir cores para as classes\ncmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])  # Vermelho claro para queda, Verde claro para alta\ncmap_bold = ListedColormap(['#FF0000', '#00FF00'])   # Vermelho para queda, Verde para alta\n\n# Plotar o limite de decis\u00e3o\nplt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n\n# Plotar os pontos de dados\nscatter = plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_sample, \n                     cmap=cmap_bold, edgecolor='black', s=30, alpha=0.7)\n\n# Configurar t\u00edtulo e labels\nplt.title(\"KNN Decision Boundary - Previs\u00e3o de Alta/Queda de A\u00e7\u00f5es\\n(Open Price vs Log Volume)\", \n          fontsize=16, fontweight='bold', pad=20)\n\nplt.xlabel(\"Pre\u00e7o de Abertura (Normalizado)\", fontsize=12)\nplt.ylabel(\"Volume (Log Normalizado)\", fontsize=12)\n\n# Adicionar grid\nplt.grid(True, linestyle='--', alpha=0.3)\n\n# Adicionar legenda\nlegend_elements = [\n    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF0000', \n               markersize=10, label='Queda (Close \u2264 Open)'),\n    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#00FF00', \n               markersize=10, label='Alta (Close &gt; Open)')\n]\nplt.legend(handles=legend_elements, loc='upper right', fontsize=11)\n\n# Adicionar informa\u00e7\u00f5es no gr\u00e1fico\nplt.text(0.02, 0.98, f'K = {knn.n_neighbors}\\nAmostras: {len(X_sample)}', \n         transform=plt.gca().transAxes, fontsize=10,\n         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\n# Adicionar anota\u00e7\u00f5es para as regi\u00f5es\nplt.text(-2, -2, 'Regi\u00e3o de Queda', fontsize=11, \n         bbox=dict(facecolor='white', alpha=0.8, edgecolor='red'))\nplt.text(1.5, 1.5, 'Regi\u00e3o de Alta', fontsize=11, \n         bbox=dict(facecolor='white', alpha=0.8, edgecolor='green'))\n\n# Ajustar layout\nplt.tight_layout()\n\n# Salvar como SVG\noutput_path = os.path.join(script_dir, 'knn_decision_boundary.svg')\nplt.savefig(output_path, format='svg', bbox_inches='tight', dpi=300)\nprint(f\" Gr\u00e1fico salvo como: {output_path}\")\n\n# Mostrar o plot\nplt.show()\n\n# Estat\u00edsticas adicionais\nprint(f\"\\n Estat\u00edsticas do modelo:\")\nprint(f\"Total de amostras: {len(X_sample)}\")\nprint(f\"Quedas: {np.sum(y_sample == 0)}\")\nprint(f\"Altas: {np.sum(y_sample == 1)}\")\naccuracy = knn.score(X_scaled, y_sample)\nprint(f\"Acur\u00e1cia no conjunto de treino: {accuracy:.3f}\")\n</code></pre>"},{"location":"KNN/main/#7-como-executar","title":"7. Como Executar","text":"<ol> <li> <p>Prepara\u00e7\u00e3o do ambiente: </p><pre><code>pip install -r requirements.txt --upgrade\n</code></pre><p></p> </li> <li> <p>Execu\u00e7\u00e3o do pipeline: </p><pre><code># Primeiro: treinar o modelo\npython KNN_model.py\n</code></pre><p></p> </li> <li> <p>Requisitos:</p> </li> <li>Arquivo <code>all_stocks_5yr.csv</code> na mesma pasta dos scripts</li> <li>Python 3.7+ instalado</li> </ol>"},{"location":"KNN/main/#8-limitacoes-e-melhorias-futuras","title":"8. Limita\u00e7\u00f5es e Melhorias Futuras","text":""},{"location":"KNN/main/#limitacoes","title":"Limita\u00e7\u00f5es:","text":"<ul> <li>Sensibilidade \u00e0 escala dos dados \u2192 Requer normaliza\u00e7\u00e3o</li> <li>Custo computacional em datasets muito grandes</li> <li>Performance pode decair em dados de alta dimensionalidade</li> </ul>"},{"location":"KNN/main/#melhorias-futuras","title":"Melhorias Futuras:","text":"<ul> <li>Otimiza\u00e7\u00e3o de hiperpar\u00e2metros com GridSearchCV</li> <li>Feature engineering adicional (indicadores t\u00e9cnicos)</li> <li>Compara\u00e7\u00e3o com outros algoritmos (Random Forest, SVM, Redes Neurais)</li> <li>Valida\u00e7\u00e3o temporal para dados financeiros</li> <li>Ensemble methods para melhorar robustez</li> </ul>"},{"location":"KNN/main/#9-conclusao","title":"9. Conclus\u00e3o","text":"<p>O modelo KNN mostrou-se eficaz para a classifica\u00e7\u00e3o de movimentos de pre\u00e7os de a\u00e7\u00f5es, oferecendo uma abordagem intuitiva e visualmente interpret\u00e1vel. A combina\u00e7\u00e3o de t\u00e9cnicas de pr\u00e9-processamento adequadas com a visualiza\u00e7\u00e3o do limite de decis\u00e3o proporciona uma ferramenta valiosa para an\u00e1lise t\u00e9cnica de a\u00e7\u00f5es.</p> <p>Pr\u00f3ximos passos: Implementar valida\u00e7\u00e3o cruzada temporal, adicionar mais features t\u00e9cnicas e comparar com modelos mais complexos.</p>"},{"location":"KNN/main/#10-referencias","title":"10. Refer\u00eancias","text":"<ul> <li>Scikit-learn documentation: KNearestNeighbors</li> <li>pandas documentation: Data manipulation</li> <li>matplotlib: Visualization techniques</li> <li>Financial Machine Learning literature</li> </ul>"},{"location":"Metrics%20and%20Evaluation/main/","title":"Metrics and Evaluation","text":""},{"location":"Metrics%20and%20Evaluation/main/#k-means-evaluation-mainmd","title":"K-Means Evaluation \u2014 main.md","text":""},{"location":"Metrics%20and%20Evaluation/main/#1-resumo-do-projeto","title":"1. Resumo do projeto","text":"<p>Este projeto avalia a aplica\u00e7\u00e3o do algoritmo K\u2011Means ao dataset <code>all_stocks_5yr.csv</code> (agrupamento de a\u00e7\u00f5es por retorno m\u00e9dio e volatilidade). Foi criado um script (<code>kmeans_evaluation.py</code>) que executa K\u2011Means para v\u00e1rios valores de K, calcula m\u00e9tricas internas de cluster e gera gr\u00e1ficos e arquivos CSV com os resultados.</p>"},{"location":"Metrics%20and%20Evaluation/main/#2-objetivo","title":"2. Objetivo","text":"<ul> <li>Aplicar K\u2011Means para agrupar empresas/a\u00e7\u00f5es segundo comportamento (retorno m\u00e9dio \u00d7 volatilidade).</li> <li>Avaliar a qualidade dos clusters usando m\u00e9tricas internas (n\u00e3o supervisionadas) e visualiza\u00e7\u00f5es.</li> <li>Gerar artefatos para incluir no relat\u00f3rio final: tabelas, gr\u00e1ficos e interpreta\u00e7\u00f5es.</li> </ul>"},{"location":"Metrics%20and%20Evaluation/main/#3-metricas-utilizadas-e-justificativa","title":"3. M\u00e9tricas utilizadas e justificativa","text":"<ul> <li>Inertia / WCSS (Within\u2011cluster Sum of Squares): usado no Elbow Method para sugerir valores de K; quantifica variabilidade interna dos clusters.</li> <li>Silhouette score (m\u00e9dia e por amostra): mede coes\u00e3o e separa\u00e7\u00e3o; valores pr\u00f3ximos de 1 indicam clusters bem definidos, valores pr\u00f3ximos a 0 indicam sobreposi\u00e7\u00e3o, negativos indicam m\u00e1 atribui\u00e7\u00e3o.</li> <li>Calinski\u2011Harabasz Index: raz\u00e3o de vari\u00e2ncia entre e dentro dos clusters; quanto maior, melhor.</li> <li>Davies\u2011Bouldin Index: m\u00e9dia da similaridade entre cada cluster e seu mais similar; quanto menor, melhor.</li> <li>Tamanho dos clusters: detectar clusters muito pequenos (poss\u00edveis outliers) ou muito grandes (subgrupos ocultos).</li> <li>Centroides: interpretar caracter\u00edsticas centrais de cada cluster (ex.: cluster com baixa volatilidade e alto retorno).</li> </ul>"},{"location":"Metrics%20and%20Evaluation/main/#4-arquivos-saidas-geradas-pelo-script","title":"4. Arquivos / Sa\u00eddas geradas pelo script","text":"<p>Ao rodar <code>kmeans_evaluation.py</code>, ser\u00e1 criada uma pasta <code>kmeans_evaluation_outputs/</code> contendo:</p> <ul> <li><code>kmeans_metrics_by_k.csv</code> \u2014 m\u00e9tricas (inertia, silhouette_mean, calinski_harabasz, davies_bouldin) para cada K testado.</li> <li><code>elbow_silhouette_by_k.png</code> \u2014 gr\u00e1fico com Elbow (inertia) e Silhouette m\u00e9dia por K.</li> <li><code>kmeans_summary.csv</code> \u2014 resumo das m\u00e9tricas para o K escolhido (por padr\u00e3o K=3).</li> <li><code>clusters_result.csv</code> \u2014 lista completa de tickers e o cluster atribu\u00eddo.</li> <li><code>cluster_summary.csv</code> \u2014 resumo por cluster (contagem, m\u00e9dia de volatilidade, m\u00e9dia de retorno).</li> <li><code>clusters_scatter_with_centroids.png</code> \u2014 scatter plot (volatilidade \u00d7 retorno) com clusters e centroides.</li> <li><code>silhouette_plot.png</code> \u2014 silhouette plot com distribui\u00e7\u00e3o por cluster.</li> </ul>"},{"location":"Metrics%20and%20Evaluation/main/#visualizacoes-geradas","title":"Visualiza\u00e7\u00f5es geradas","text":"<p> Elbow (Inertia) e Silhouette m\u00e9dia por K \u2014 ajuda a selecionar K.</p> <p> Scatter plot (volatilidade \u00d7 retorno) com os clusters encontrados e centroides marcados.</p> <p> Silhouette por amostra, mostrando a qualidade das atribui\u00e7\u00f5es por cluster.</p>"},{"location":"Metrics%20and%20Evaluation/main/#5-interpretacao-rapida-dos-resultados-o-que-incluir-no-relatorio","title":"5. Interpreta\u00e7\u00e3o r\u00e1pida dos resultados (o que incluir no relat\u00f3rio)","text":"<ul> <li>Compare Inertia e Silhouette mean para escolher K: o elbow sugere K onde a redu\u00e7\u00e3o de inertia diminui abruptamente; o K que maximiza a silhouette m\u00e9dia tamb\u00e9m \u00e9 um bom candidato.</li> <li>Use o silhouette per sample para identificar a\u00e7\u00f5es mal atribu\u00eddas (valores negativos ou muito baixos) e discuta poss\u00edveis raz\u00f5es (outliers, features insuficientes).</li> <li>Quando Calinski e Davies\u2011Bouldin concordarem com silhouette, a confian\u00e7a no K escolhido aumenta. Caso haja diverg\u00eancia, discuta trade\u2011offs.</li> <li>Analise os centroides e tamanhos de cluster para fornecer interpreta\u00e7\u00f5es qualitativas (ex.: Cluster A = baixa volatilidade, retorno moderado \u2192 perfil conservador).</li> </ul>"},{"location":"Metrics%20and%20Evaluation/main/#6-referencias","title":"6. Refer\u00eancias","text":"<ul> <li>Reposit\u00f3rio analisado: <code>all_stocks_5yr.csv</code> (implementa\u00e7\u00e3o original do exerc\u00edcio K\u2011Means).</li> <li>Material de m\u00e9tricas e conceitos (para apoiar o relat\u00f3rio): artigos e documenta\u00e7\u00e3o sobre Silhouette, Calinski\u2011Harabasz, Davies\u2011Bouldin e Elbow Method.</li> </ul>"},{"location":"Randon-Forest/main/","title":"Random Forest","text":""},{"location":"Randon-Forest/main/#previsao-de-tendencia-de-acoes-com-random-forest","title":"Previs\u00e3o de Tend\u00eancia de A\u00e7\u00f5es com Random Forest","text":""},{"location":"Randon-Forest/main/#etapa-1-exploracao-dos-dados","title":"Etapa 1 \u2013 Explora\u00e7\u00e3o dos Dados","text":"<p>O conjunto de dados utilizado cont\u00e9m informa\u00e7\u00f5es hist\u00f3ricas de pre\u00e7os de diversas a\u00e7\u00f5es do mercado americano, incluindo as colunas:</p> <ul> <li>date: data da cota\u00e7\u00e3o  </li> <li>open: pre\u00e7o de abertura  </li> <li>high: pre\u00e7o m\u00e1ximo do dia  </li> <li>low: pre\u00e7o m\u00ednimo do dia  </li> <li>close: pre\u00e7o de fechamento  </li> <li>volume: n\u00famero de a\u00e7\u00f5es negociadas  </li> <li>Name: ticker da empresa  </li> </ul> <p>Durante a an\u00e1lise inicial, foi poss\u00edvel observar que os pre\u00e7os variam consideravelmente entre empresas e ao longo do tempo. As colunas num\u00e9ricas apresentaram valores cont\u00ednuos e consistentes, ideais para uso em modelos de aprendizado supervisionado.</p>"},{"location":"Randon-Forest/main/#etapa-2-pre-processamento","title":"Etapa 2 \u2013 Pr\u00e9-processamento","text":"<p>Foi realizada a limpeza e prepara\u00e7\u00e3o dos dados: - Remo\u00e7\u00e3o de valores ausentes (<code>NaN</code>) nas colunas principais (<code>open</code>, <code>high</code>, <code>low</code>, <code>close</code>, <code>volume</code>); - Cria\u00e7\u00e3o da vari\u00e1vel alvo (<code>target</code>), que indica se o pre\u00e7o subiu (1) ou caiu (0) no dia seguinte:   [   target =    \\begin{cases}    1, &amp; \\text{se } close_{t+1} &gt; close_t \\   0, &amp; \\text{caso contr\u00e1rio}   \\end{cases}   ] - Nenhuma normaliza\u00e7\u00e3o adicional foi aplicada, pois os modelos de \u00e1rvore n\u00e3o exigem escalonamento de dados.</p>"},{"location":"Randon-Forest/main/#etapa-3-divisao-dos-dados","title":"Etapa 3 \u2013 Divis\u00e3o dos Dados","text":"<p>Os dados foram divididos em: - Treino: 75% - Teste: 25%</p> <p>Essa separa\u00e7\u00e3o permite avaliar o desempenho do modelo em dados nunca vistos, evitando overfitting.</p>"},{"location":"Randon-Forest/main/#etapa-4-treinamento-do-modelo","title":"Etapa 4 \u2013 Treinamento do Modelo","text":"<p>O modelo escolhido foi o Random Forest Classifier, com os principais hiperpar\u00e2metros: - <code>n_estimators = 200</code> - <code>random_state = 42</code> - <code>n_jobs = -1</code> (para paralelismo)  </p> <p>O modelo foi treinado com as features: <code>open</code>, <code>high</code>, <code>low</code>, <code>close</code>, <code>volume</code>.</p> <p>O objetivo \u00e9 prever se o pre\u00e7o de fechamento da a\u00e7\u00e3o no pr\u00f3ximo dia ser\u00e1 maior (1) ou menor (0) que o do dia atual.</p>"},{"location":"Randon-Forest/main/#etapa-5-avaliacao-do-modelo","title":"Etapa 5 \u2013 Avalia\u00e7\u00e3o do Modelo","text":""},{"location":"Randon-Forest/main/#relatorio-de-classificacao","title":"\ud83d\udd39 Relat\u00f3rio de Classifica\u00e7\u00e3o","text":"Classe Precision Recall F1-score Suporte 0 (queda) 0.48 0.44 0.46 74 109 1 (alta) 0.52 0.56 0.54 80 648 <p>Acur\u00e1cia geral: 0.50 M\u00e9dia ponderada (weighted avg): 0.50  </p>"},{"location":"Randon-Forest/main/#interpretacao-dos-resultados","title":"Interpreta\u00e7\u00e3o dos Resultados","text":"<p>O modelo apresentou acur\u00e1cia de 50%, indicando desempenho equivalente a uma previs\u00e3o aleat\u00f3ria. Isso ocorre porque a varia\u00e7\u00e3o di\u00e1ria do pre\u00e7o das a\u00e7\u00f5es \u00e9 altamente vol\u00e1til e depende de fatores externos (not\u00edcias, economia global, eventos corporativos) n\u00e3o presentes nos dados num\u00e9ricos usados.</p> <p>Apesar do baixo desempenho, as m\u00e9tricas mostram: - Um ligeiro vi\u00e9s positivo (classe <code>1</code> \u2013 subida) foi melhor identificada pelo modelo; - As classes est\u00e3o razoavelmente balanceadas, o que torna a acur\u00e1cia um bom indicador; - A import\u00e2ncia das vari\u00e1veis indica que as features mais relevantes foram:   - <code>close</code> (fechamento do dia anterior);   - <code>high</code> e <code>low</code>, que refletem volatilidade di\u00e1ria;   - <code>volume</code>, com menor peso.</p>"},{"location":"Randon-Forest/main/#visualizacoes","title":"Visualiza\u00e7\u00f5es","text":""},{"location":"Randon-Forest/main/#matriz-de-confusao","title":"Matriz de Confus\u00e3o","text":""},{"location":"Randon-Forest/main/#importancia-das-variaveis","title":"Import\u00e2ncia das Vari\u00e1veis","text":""},{"location":"Randon-Forest/main/#etapa-6-relatorio-final","title":"Etapa 6 \u2013 Relat\u00f3rio Final","text":""},{"location":"Randon-Forest/main/#conclusoes","title":"Conclus\u00f5es","text":"<ul> <li>O modelo Random Forest foi implementado com sucesso e executou previs\u00f5es bin\u00e1rias sobre a tend\u00eancia de pre\u00e7o di\u00e1rio.  </li> <li>O desempenho de 50% de acur\u00e1cia mostra que, sem vari\u00e1veis externas (not\u00edcias, indicadores econ\u00f4micos ou de sentimento), \u00e9 dif\u00edcil prever movimentos de curto prazo no mercado de a\u00e7\u00f5es.  </li> <li>O modelo, contudo, demonstra corretamente a aplica\u00e7\u00e3o do m\u00e9todo e a pipeline de Machine Learning.</li> </ul>"},{"location":"Randon-Forest/main/#possiveis-melhorias","title":"Poss\u00edveis Melhorias","text":"<ul> <li>Adicionar novas features, como m\u00e9dias m\u00f3veis ou retornos percentuais acumulados;  </li> <li>Incluir vari\u00e1veis de contexto, como indicadores econ\u00f4micos (ex: S&amp;P500, juros, infla\u00e7\u00e3o);  </li> <li>Testar modelos sequenciais (ex: LSTM, Prophet) mais adequados para s\u00e9ries temporais.</li> </ul>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.git </p> <p>ljcbksdcbajhbasjhcsaic</p>"},{"location":"roteiro%201/main/","title":"Roteiro 1","text":""},{"location":"roteiro%201/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"roteiro%201/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"roteiro%201/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"roteiro%201/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiro%201/main/#app","title":"App","text":""},{"location":"roteiro%201/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"roteiro%201/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"roteiro%201/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"roteiro%201/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"roteiro%201/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"roteiro%202/main/","title":"Roteiro 2","text":""},{"location":"roteiro%202/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiro%202/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiro%203/main/","title":"Roteiro 3","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> </p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> <p></p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiro%204/main/","title":"Roteiro 4","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> <p></p> <p></p> <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"}]}